{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.0.0-beta1\n",
      "  Using cached tensorflow-2.0.0b1-cp37-cp37m-win_amd64.whl (55.1 MB)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (0.9.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (3.12.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (0.3.3)\n",
      "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501\n",
      "  Downloading tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496 kB)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (1.1.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (1.14.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (1.18.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
      "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603\n",
      "  Downloading tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (0.34.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (1.11.2)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow==2.0.0-beta1) (1.30.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta1) (45.2.0.post20200210)\n",
      "Requirement already satisfied: h5py in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.10.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (2.2.0)\n",
      "Installing collected packages: tf-estimator-nightly, keras-applications, tb-nightly, astor, tensorflow\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed astor-0.8.1 keras-applications-1.0.8 tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1.1; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hp\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.0.0-beta1\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./traffice-signs-data/train.p\", mode='rb') as training_data:\n",
    "    train = pickle.load(training_data)\n",
    "with open(\"./traffice-signs-data/valid.p\", mode='rb') as validation_data:\n",
    "    valid = pickle.load(validation_data)\n",
    "with open(\"./traffice-signs-data/train.p\", mode='rb') as testing_data:\n",
    "    test = pickle.load(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , y_train = train['features'], train['labels']\n",
    "X_valid , y_valid = valid['features'], valid['labels']\n",
    "X_test , y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 3 IMage visulaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(1, len(X_train))\n",
    "plt.imshow(X_train[i])\n",
    "y_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define The dimnensions of the plot grid'''\n",
    "W_grid=5\n",
    "L_grid=5\n",
    "# fig, axes = plt.subplots(L_grid,W_grid)\n",
    "# subplot return the figure object and axes object\n",
    "# we can use the axes object to plot specific fig at various locations\n",
    "\n",
    "fig, axes = plt.subplots(L_grid,W_grid,figsize=(10,10)) \n",
    "axes = axes.ravel() # Flatten the 5x5 matrix into 25 array\n",
    "n_training = len(X_train) #get the len of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0,W_grid*L_grid):\n",
    "    index = np.random.randint(0,n_training)\n",
    "    \n",
    "    axes[i].imshow(X_train[index])\n",
    "    axes[i].set_title(y_train[index], fontsize = 15)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "plt.subplots_adjust(hspace=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## task 4 convert image to gray scale and perform normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray = np.sum(X_train/3, axis=3, keepdims=True)\n",
    "X_valid_gray = np.sum(X_valid/3, axis=3, keepdims=True)\n",
    "X_test_gray = np.sum(X_test/3, axis=3, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray.shape\n",
    "# output = (34799,32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "X_train_gray_norm = (X_train_gray-128)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray_norm\n",
    "# Output = normalize data (all values of images is between 0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 6: Build deep CNN model\n",
    "\n",
    "from tensorflow.keras import datasets, layeres,models\n",
    "\n",
    "CNN = models.Sequential()\n",
    "\n",
    "CNN.add(layers.Conv2D(6,(5,5),activation='relu', input_shape=(32,32,1)))\n",
    "CNN.add(layers.AveragePooling2D())\n",
    "\n",
    "CNN.add(layers.Dropout(0.2))\n",
    "\n",
    "CNN.add(layers.Conv2D(16,(5,5),activation='relu'))\n",
    "CNN.add(layers.AveragePooling2D())\n",
    "\n",
    "CNN.add(layers.Flatten())\n",
    "\n",
    "CNN.add(layers.Dense(120,activation='relu'))\n",
    "CNN.add(layers.Dense(84,activation='relu'))\n",
    "CNN.add(layers.Dense(43,activation='softmax'))\n",
    "\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 7 Compile and train CNN model\n",
    "CNN.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = CNN.fit(X_train_gray_norm,\n",
    "                 y_train,\n",
    "                 epochs =5,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_validation_gray_norm,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 8\n",
    "\n",
    "score  = CNN.evaluate(X_test_gray_norm, y_test)\n",
    "print('Test Accuracy: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss= history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, loss,'ro',label='Training loss')\n",
    "plt.plot(epochs, val_loss,'r',label='Validation loss')\n",
    "plt.title('Training and Validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy,'ro',label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy,'r',label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = CNN.predict_classes(X_test_gray_norm)\n",
    "\n",
    "y_true = y_test\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, predicted_classes) \n",
    "plt.figure(figsize=(25,25))\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=5\n",
    "W=5\n",
    "\n",
    "fig, axes = plt.subplots(L,W, figsize=(12,12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in np.arange(0, L*W):\n",
    "    axes[i].imshow(X_test[i])\n",
    "    axes[i].set_title('Prediction = {}\\n True = {}'.format(predicted_classes[i], y_true[i]))\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "plt.subplots_adjust(wspace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
